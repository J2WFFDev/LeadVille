            # Enhanced per-sensor calibration with individual sensor baselines
            self.logger.info("ðŸŽ¯ Calibration collection completed for all sensors!")
            self.logger.info(f"ðŸ“Š Detailed Per-Sensor Calibration Analysis:")
            self.logger.info(f"ðŸ“ˆ Total samples collected: {len(self.calibration_samples)}")
            
            # Store individual sensor baselines (this is the key change!)
            self.individual_sensor_baselines = {}
            
            # Analyze calibration data by clustering samples (sensors have different baselines)
            vx_values = [s['vx_raw'] for s in self.calibration_samples]
            vy_values = [s['vy_raw'] for s in self.calibration_samples]
            vz_values = [s['vz_raw'] for s in self.calibration_samples]
            
            import statistics
            from collections import defaultdict
            
            # Sort by X values to find natural sensor clusters
            vx_sorted = sorted(self.calibration_samples, key=lambda x: x['vx_raw'])
            vx_values_sorted = [s['vx_raw'] for s in vx_sorted]
            
            # Find the gap in X values to split into two sensor groups
            if len(vx_values_sorted) > 1:
                diffs = [vx_values_sorted[i+1] - vx_values_sorted[i] for i in range(len(vx_values_sorted)-1)]
                max_gap_idx = diffs.index(max(diffs))
                split_value = (vx_values_sorted[max_gap_idx] + vx_values_sorted[max_gap_idx + 1]) / 2
                
                # Split samples into two groups based on X value
                sensor_groups = defaultdict(list)
                for sample in self.calibration_samples:
                    if sample['vx_raw'] <= split_value:
                        sensor_groups[0].append(sample)
                    else:
                        sensor_groups[1].append(sample)
                        
                self.logger.info(f"ðŸ“Š Sensor detection: Split at X={split_value:.0f}")
                self.logger.info(f"ðŸ“Š Group sizes: {len(sensor_groups[0])} + {len(sensor_groups[1])}")
            else:
                sensor_groups = {0: self.calibration_samples}
            
            # Create individual baselines for each sensor
            sensor_names = ['BAE5', '5550']
            for i, (group_id, samples) in enumerate(sensor_groups.items()):
                if len(samples) < 10:  # Need minimum samples
                    continue
                    
                sensor_name = sensor_names[i] if i < len(sensor_names) else f"Sensor_{group_id+1}"
                    
                vx_group = [s['vx_raw'] for s in samples]
                vy_group = [s['vy_raw'] for s in samples]
                vz_group = [s['vz_raw'] for s in samples]
                
                # Calculate individual sensor baseline
                baseline_x = int(sum(vx_group) / len(vx_group))
                baseline_y = int(sum(vy_group) / len(vy_group))
                baseline_z = int(sum(vz_group) / len(vz_group))
                
                noise_x = statistics.stdev(vx_group) if len(set(vx_group)) > 1 else 0
                noise_y = statistics.stdev(vy_group) if len(set(vy_group)) > 1 else 0
                noise_z = statistics.stdev(vz_group) if len(set(vz_group)) > 1 else 0
                
                # Store individual sensor baseline
                self.individual_sensor_baselines[sensor_name] = {
                    'baseline_x': baseline_x,
                    'baseline_y': baseline_y,
                    'baseline_z': baseline_z,
                    'noise_x': noise_x,
                    'noise_y': noise_y,
                    'noise_z': noise_z,
                    'sample_count': len(samples)
                }
                
                # Log individual sensor analysis to console log
                self.logger.info(f"ðŸ“Š {sensor_name} Individual Calibration:")
                self.logger.info(f"   ðŸ“ˆ Samples collected: {len(samples)}")
                self.logger.info(f"   ðŸ“ Individual Baseline: X={baseline_x:+05d}, Y={baseline_y:+05d}, Z={baseline_z:+05d}")
                self.logger.info(f"   ðŸ“ Noise (Â±1Ïƒ): X=Â±{noise_x:.1f}, Y=Â±{noise_y:.1f}, Z=Â±{noise_z:.1f}")
                self.logger.info(f"   ðŸ”§ Zero adjustment: X={abs(baseline_x)}, Y={abs(baseline_y)}, Z={abs(baseline_z)} counts")
                self.logger.info(f"   ðŸ“ˆ 95% confidence (Â±2Ïƒ): X=Â±{2*noise_x:.1f}, Y=Â±{2*noise_y:.1f}, Z=Â±{2*noise_z:.1f}")

            # Set system baseline to first sensor for compatibility, but each sensor uses its own
            if self.individual_sensor_baselines:
                first_sensor = list(self.individual_sensor_baselines.keys())[0]
                self.baseline_x = self.individual_sensor_baselines[first_sensor]['baseline_x']
                self.baseline_y = self.individual_sensor_baselines[first_sensor]['baseline_y']
                self.baseline_z = self.individual_sensor_baselines[first_sensor]['baseline_z']
                
                self.logger.info(f"ðŸŽ¯ Individual Sensor Calibration Complete:")
                self.logger.info(f"   ðŸ“Š {len(self.individual_sensor_baselines)} sensors individually calibrated")
                self.logger.info(f"   ðŸŽ¯ Each sensor will use its own baseline for impact detection")
            else:
                # Fallback to combined approach
                self.baseline_x = int(sum(vx_values) / len(vx_values))
                self.baseline_y = int(sum(vy_values) / len(vy_values))
                self.baseline_z = int(sum(vz_values) / len(vz_values))

            # Calculate noise characteristics for compatibility
            import statistics
            noise_x = statistics.stdev(vx_values) if len(set(vx_values)) > 1 else 0
            noise_y = statistics.stdev(vy_values) if len(set(vy_values)) > 1 else 0
            noise_z = statistics.stdev(vz_values) if len(set(vz_values)) > 1 else 0